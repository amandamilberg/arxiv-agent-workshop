{"custom_id": "2401.00001v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Efficient Inference for Large Language Models: A Survey\n\nAbstract:\nLarge Language Models (LLMs) have revolutionized natural language processing but face significant challenges in deployment due to their computational requirements. This survey comprehensively reviews recent advances in efficient LLM inference, covering techniques such as quantization, pruning, knowledge distillation, and speculative decoding. We analyze the trade-offs between efficiency and model quality, providing practitioners with actionable guidance for deploying LLMs in resource-constrained environments. Our analysis covers over 100 recent papers and includes benchmarks across various model sizes and hardware configurations.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00002v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: ReAct Agents: Combining Reasoning and Acting in Language Models\n\nAbstract:\nWe present an improved framework for building AI agents that interleave reasoning traces with actions. Our approach enables language models to generate verbal reasoning traces while simultaneously taking actions in an environment. This synergy allows for dynamic reasoning and plan adjustment, leading to improved performance on knowledge-intensive tasks and decision-making benchmarks. We demonstrate substantial improvements on HotpotQA, Fever, and interactive web navigation tasks, achieving state-of-the-art results while providing interpretable decision traces.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00003v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Prompt Engineering Best Practices for Production Systems\n\nAbstract:\nAs large language models become integral to production systems, effective prompt engineering has emerged as a critical skill. This paper presents a systematic study of prompt engineering techniques across 15 enterprise use cases. We introduce a taxonomy of prompting strategies and evaluate their effectiveness across different model families. Our findings reveal that structured prompting with examples improves accuracy by 23% on average, while chain-of-thought prompting excels in mathematical reasoning tasks. We release a benchmark suite for evaluating prompt effectiveness.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00004v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Scaling Laws for Fine-tuning Language Models\n\nAbstract:\nWe investigate scaling laws that govern the fine-tuning of large language models. Through extensive experiments across model sizes from 125M to 70B parameters, we characterize how fine-tuning data requirements, learning rates, and compute budgets scale with model size. Our findings challenge conventional wisdom: larger models often require less fine-tuning data to achieve equivalent downstream performance. We derive practical guidelines for allocating fine-tuning resources and introduce a cost-optimal fine-tuning calculator.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00005v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Tool Use in Large Language Models: A Comprehensive Survey\n\nAbstract:\nThe ability of large language models to use external tools represents a significant advance toward artificial general intelligence. This survey systematically reviews tool-augmented LLMs, covering tool selection, invocation, and result integration. We categorize tools into computational, retrieval, and action-based types, analyzing how different architectures handle each category. Our analysis reveals key challenges including tool hallucination, context management, and error recovery. We propose a evaluation framework and benchmark suite for measuring tool-use capabilities.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00006v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Retrieval-Augmented Generation: Reducing Hallucinations in LLMs\n\nAbstract:\nHallucination remains one of the most significant challenges in deploying large language models for factual tasks. We present RAG-Verify, a novel retrieval-augmented generation system that substantially reduces hallucinations while maintaining fluency. Our approach combines dense retrieval with a verification module that cross-references generated claims against retrieved documents. Experiments on TruthfulQA, Natural Questions, and a new enterprise fact-checking benchmark show a 67% reduction in hallucinations compared to baseline models with minimal impact on generation speed.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00007v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Constitutional AI: Alignment through Self-Improvement\n\nAbstract:\nWe explore methods for training AI systems to be helpful, harmless, and honest through self-improvement techniques. Our Constitutional AI approach uses a set of principles to guide model behavior without requiring extensive human feedback on harmful outputs. The model critiques and revises its own outputs according to constitutional principles. We demonstrate that this approach achieves comparable safety levels to RLHF while reducing the need for human labeling of harmful content by 90%. We release our constitutional principles as a resource for the community.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00008v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Multi-Agent Collaboration with Large Language Models\n\nAbstract:\nComplex tasks often benefit from multiple specialized agents working together. We present AgentCollab, a framework for orchestrating multiple LLM-powered agents in collaborative problem-solving. Our approach includes specialized agents for planning, research, coding, and critique, coordinated by a meta-agent. On software development benchmarks, AgentCollab outperforms single-agent approaches by 34% while providing better transparency through explicit inter-agent communication. We analyze failure modes and propose strategies for robust multi-agent coordination.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00009v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Quantization Techniques for Efficient LLM Deployment\n\nAbstract:\nDeploying large language models on edge devices and consumer hardware requires aggressive model compression. We present a comprehensive study of quantization techniques, comparing post-training quantization, quantization-aware training, and mixed-precision approaches. Our experiments span models from 7B to 70B parameters across various quantization levels (INT8, INT4, and lower). We introduce AdaptiveQuant, a method that achieves 4-bit quantization with less than 1% accuracy degradation. We release optimized kernels for common hardware platforms.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00010v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Evaluating Large Language Models: Challenges and Best Practices\n\nAbstract:\nThe rapid advancement of large language models has outpaced the development of reliable evaluation methods. This paper addresses the evaluation crisis by proposing a multi-dimensional assessment framework. We identify key failure modes in current benchmarks including data contamination, metric gaming, and task saturation. Our framework incorporates robustness testing, calibration analysis, and human preference alignment. We validate our approach across 10 state-of-the-art models and release an evaluation toolkit for practitioners.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00011v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Long Context Understanding in Transformer Models\n\nAbstract:\nProcessing long documents remains challenging for transformer-based language models due to quadratic attention complexity. We present LongFormer-X, an architecture modification that extends context length to 128K tokens while maintaining computational efficiency. Our approach combines sparse attention patterns with hierarchical summarization, enabling effective information retrieval across extremely long documents. We demonstrate state-of-the-art performance on narrative understanding, legal document analysis, and code repository comprehension tasks.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00012v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Code Generation with Large Language Models: A Practical Guide\n\nAbstract:\nLarge language models have demonstrated remarkable code generation capabilities, yet their practical deployment requires careful consideration of reliability, security, and integration. This paper provides a comprehensive guide for deploying LLM-based code generation in production environments. We cover prompt engineering for code, output validation, security scanning, and integration with development workflows. Our case studies from three enterprise deployments reveal common pitfalls and best practices for maximizing developer productivity while minimizing risks.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00013v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Speculative Decoding: Accelerating LLM Inference Without Quality Loss\n\nAbstract:\nWe present an improved speculative decoding method that accelerates large language model inference by 2-3x without any degradation in output quality. Our approach uses a small draft model to propose multiple tokens, which are then verified in parallel by the target model. We introduce adaptive speculation depth that adjusts based on generation confidence and context. Experiments across diverse tasks show consistent speedups while maintaining identical output distributions to standard autoregressive decoding.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00014v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Instruction Following in Large Language Models\n\nAbstract:\nThe ability to follow complex, multi-step instructions is crucial for practical AI applications. We present InstructBench, a comprehensive benchmark for evaluating instruction-following capabilities across 15 dimensions including constraint satisfaction, format adherence, and compositional generalization. Our analysis of 20 frontier models reveals significant gaps between human and model performance, particularly for instructions requiring precise numerical constraints or multi-step reasoning. We identify training strategies that improve instruction following and release our benchmark.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00015v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Mixture of Experts for Efficient Large Language Models\n\nAbstract:\nMixture of Experts (MoE) architectures offer a path to scaling language models efficiently by activating only a subset of parameters for each input. We present MoE-LLM, a comprehensive study of sparse MoE architectures for language modeling. Our analysis covers routing strategies, expert specialization, load balancing, and training stability. We introduce novel techniques for expert selection that improve both efficiency and quality, achieving GPT-4-level performance with 40% fewer activated parameters during inference.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00016v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Theory of Mind in Large Language Models: An Empirical Investigation\n\nAbstract:\nUnderstanding and predicting others mental states (theory of mind) is fundamental to human social cognition. We investigate whether large language models exhibit theory of mind capabilities through a battery of tests including false belief tasks, intention recognition, and perspective-taking challenges. Our experiments reveal nuanced findings: while LLMs succeed on many classic theory of mind tests, they fail systematically on tasks requiring tracking of nested beliefs or implicit mental state inference. We analyze failure patterns and their implications for AI applications in social contexts.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00017v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Safety Alignment in Large Language Models: Methods and Challenges\n\nAbstract:\nEnsuring large language models behave safely and according to human values is a critical challenge. This survey reviews safety alignment techniques including RLHF, constitutional AI, red teaming, and adversarial training. We categorize safety concerns into harmful content generation, privacy violations, and manipulation risks, analyzing how different alignment methods address each category. Our experimental comparison across alignment approaches reveals trade-offs between safety and capability, and we identify open problems for future research.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00018v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: In-Context Learning: Understanding How LLMs Learn from Examples\n\nAbstract:\nIn-context learning enables language models to perform new tasks from just a few examples without parameter updates. We present a mechanistic analysis of how in-context learning works in transformer models. Through careful experiments with synthetic data and interpretability techniques, we identify attention patterns and internal representations responsible for task inference. Our findings suggest that larger models develop more sophisticated task identification mechanisms. We provide practical guidelines for constructing effective in-context examples.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00019v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Deployment Patterns for LLM Applications in Production\n\nAbstract:\nDeploying large language model applications in production environments presents unique challenges around latency, cost, reliability, and observability. Drawing from experience deploying LLM applications at scale, we present a catalog of deployment patterns and anti-patterns. Topics include batching strategies, caching approaches, fallback mechanisms, prompt versioning, and monitoring for quality degradation. We provide reference architectures for common use cases and quantify the impact of different architectural choices on system performance.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
{"custom_id": "2401.00020v1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8", "max_tokens": 500, "messages": [{"role": "user", "content": "You are evaluating research papers for an AI engineering team.\n\nTEAM PROFILE:\nThe team is building AI-powered applications and wants to stay\n        current with the latest research on language models, inference\n        optimization, and practical AI engineering.\n\nWhat they find valuable:\n  - Large language model architectures and improvements\n  - Inference optimization and cost reduction\n  - Prompt engineering and techniques\n  - AI agents and tool use\n  - Evaluation methods for LLMs\n\nWhat to avoid recommending:\n  - Pure theoretical papers without practical applications\n  - Incremental benchmark improvements\n  - Papers focused only on training from scratch\n\n---\n\nPAPER TO EVALUATE:\n\nTitle: Advanced Topics in Transformer Architecture Design\n\nAbstract:\nSince the introduction of the transformer architecture, numerous modifications have been proposed to improve efficiency, capability, and training dynamics. This paper provides a comprehensive analysis of architectural innovations including various attention mechanisms (linear, sparse, local-global), normalization strategies (pre-norm, post-norm, RMSNorm), positional encoding schemes (rotary, ALiBi, relative), and activation functions. We conduct systematic ablation studies to isolate the contribution of each modification, providing practitioners with evidence-based guidance for architecture selection.\n\n---\n\nINSTRUCTIONS:\nScore this paper's relevance to the team on a scale of 0-10.\n- 0-3: Not relevant\n- 4-6: Somewhat relevant\n- 7-10: Highly relevant, team should read this\n\nRespond with ONLY valid JSON in this exact format:\n{\n    \"relevance_score\": <integer 0-10>,\n    \"key_insight\": \"<one sentence explaining the main takeaway>\",\n    \"why_relevant\": \"<one sentence explaining why this score>\"\n}"}]}}
